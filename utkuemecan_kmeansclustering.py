# -*- coding: utf-8 -*-
"""UtkuEmecan_KMeansClustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11pscLw8-GZfwjl0RO2rurWAyMBA74YVa
"""

from sklearn.datasets import fetch_olivetti_faces

data = fetch_olivetti_faces(shuffle=True, random_state=42)
images = data.images
labels = data.target

from sklearn.model_selection import train_test_split

X_temp, X_test, y_temp, y_test = train_test_split(images, labels, test_size=0.2, stratify=labels, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)

from sklearn.model_selection import cross_val_score
from sklearn.svm import SVC
from sklearn.pipeline import make_pipeline
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

X_train_flat = X_train.reshape((X_train.shape[0], -1))
X_val_flat = X_val.reshape((X_val.shape[0], -1))

pipeline = make_pipeline(StandardScaler(), PCA(n_components=150, whiten=True), SVC(kernel='rbf', class_weight='balanced'))
scores = cross_val_score(pipeline, X_train_flat, y_train, cv=5)

print("Mean cross-validation accuracy: {:.2f}".format(scores.mean()))

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

sil_scores = []
k_values = list(range(2, 20))
for k in k_values:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_train_flat)
    score = silhouette_score(X_train_flat, kmeans.labels_)
    sil_scores.append(score)

optimal_k = k_values[sil_scores.index(max(sil_scores))]

print(f"Optimal number of clusters: {optimal_k}")

kmeans = KMeans(n_clusters=optimal_k, random_state=42).fit(X_train_flat)
X_train_reduced = kmeans.transform(X_train_flat)
X_val_reduced = kmeans.transform(X_val_flat)

pipeline_without_pca = make_pipeline(StandardScaler(), SVC(kernel='rbf', class_weight='balanced'))
scores = cross_val_score(pipeline_without_pca, X_train_reduced, y_train, cv=5)

print("Mean cross-validation accuracy after dimensionality reduction: {:.2f}".format(scores.mean()))

from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train_flat)

dbscan = DBSCAN(eps=0.5, min_samples=5)
clusters = dbscan.fit_predict(X_scaled)

n_clusters = len(set(clusters)) - (1 if -1 in clusters else 0)
print(f"Number of clusters: {n_clusters}")